{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow. Word Generation with LSTM (existing model)\n",
    "\n",
    "Word generation in NLP involves creating meaningful text. Google TensorFlow, an open-source machine learning framework, offers tools to build and train models for this. This notebook covers the basics, capabilities, applications, and steps to develop word generation models using TensorFlow.\n",
    "\n",
    "![](./assets/cover.jpg)\n",
    "\n",
    "Blog Post: [TensorFlow. Word Generation with LSTM](https://vitalyzhukov.com/en/tensorflow-word-generation-with-lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "To work with TensorFlow models, you will need two libraries open-source Python libraries: NumPy (Numerical Python) and TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"./model/model_word_generation.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load tokenizer instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(open(\"./model/model_tokenizer.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_character(prefix, crazy_index:int):\n",
    "    \"\"\"Predict next characters\n",
    "\n",
    "    :param prefix: Existing part of the word\n",
    "    :param crazy_index: The number of predicted characters is used to choose one.\n",
    "    :return: Predicted character\n",
    "    \"\"\"\n",
    "    encoded = tokenizer.texts_to_sequences([prefix])\n",
    "    encoded = tf.keras.utils.pad_sequences(encoded, maxlen=50, padding=\"pre\")\n",
    "    predicted_characters = np.asarray(model.predict(encoded, verbose=0, batch_size=1)[0]).astype('float64')\n",
    "    \n",
    "    if crazy_index is None or crazy_index == 0:\n",
    "        return np.argmax(predicted_characters)\n",
    "    else:\n",
    "        if crazy_index > len(predicted_characters) : crazy_index = len(predicted_characters)\n",
    "        \n",
    "        # getting top {crazy_index} possible characters\n",
    "        candidate_args = np.argsort(predicted_characters, axis=0)[-crazy_index:]\n",
    "        probas = np.take(predicted_characters, candidate_args)\n",
    "        \n",
    "        # randomly get one the top possible characters\n",
    "        probas = np.random.multinomial(1, np.exp(np.arctan(probas))/np.sum(np.exp(np.arctan(probas))),1)\n",
    "        \n",
    "        return candidate_args[np.argmax(probas)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words(prefix, no_words:int, crazy_index:int):\n",
    "    \"\"\"Generate words\n",
    "\n",
    "    :param prefix: Existing part of the word\n",
    "    :param no_words: Number of words to generate\n",
    "    :param crazy_index: The number of predicted characters is used to choose one.\n",
    "    :return: List of generated words\n",
    "    \"\"\"\n",
    "    max_text_lenght = 20\n",
    "    meta_token = tokenizer.word_index[\"<END>\"]  \n",
    "    words = []\n",
    "    \n",
    "    for _ in range(no_words):\n",
    "        word_prefix = prefix\n",
    "        for _ in range(max_text_lenght):\n",
    "            predicted_character = predict_next_character(word_prefix, crazy_index)\n",
    "            \n",
    "            # stop prediction if the next character is the meta token presenting end of word\n",
    "            if predicted_character == meta_token:\n",
    "                break\n",
    "            \n",
    "            # convert tensor to character\n",
    "            predicted_char = tokenizer.sequences_to_texts([[predicted_character]])\n",
    "            \n",
    "            # append the character to the result word\n",
    "            word_prefix = word_prefix + predicted_char[0]\n",
    "                \n",
    "        words.append(word_prefix)\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_words(\"\", 10, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
